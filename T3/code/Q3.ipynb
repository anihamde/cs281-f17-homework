{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "range_boundaries = Variable(torch.Tensor([-4,-2,0,2,4,100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logpost(w,sig,x,ratings): # w is Embedding, sig is Variable, x is input data in tensor form, ratings is just ratings                 \n",
    "    h = torch.sum(w(x),1).squeeze()\n",
    "    \n",
    "    lefts = range_boundaries[ratings]\n",
    "    rights = range_boundaries[ratings+1]\n",
    "    \n",
    "    normlogcdflik = utils.log_difference((rights-h)/(sig),(lefts-h)/(sig))\n",
    "    \n",
    "    normlogcdfprior = -0.5*torch.sum(w(usefulvec)*w(usefulvec))\n",
    "    \n",
    "    return torch.sum(normlogcdfprior+normlogcdflik)\n",
    "\n",
    "def rangeval(val):\n",
    "    if val < range_boundaries.data.numpy()[1]:\n",
    "        return 0\n",
    "    elif val < range_boundaries.data.numpy()[2]:\n",
    "        return 1\n",
    "    elif val < range_boundaries.data.numpy()[3]:\n",
    "        return 2\n",
    "    elif val < range_boundaries.data.numpy()[4]:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "    \n",
    "def predict(itergroup,w):\n",
    "    rmses = 0\n",
    "    cntr = 0\n",
    "    batchcntr = 0\n",
    "    \n",
    "    for batch in itergroup:\n",
    "        text = batch.text[0]\n",
    "        ratings = batch.ratings-1\n",
    "        \n",
    "        h = torch.sum(w(text),1).squeeze()\n",
    "        \n",
    "#         hlist = h.data.numpy().to\n",
    "        \n",
    "        vecfunc = np.vectorize(rangeval)\n",
    "#         rmsevec = np.apply_along_axis(rangeval,0,h.data.numpy())\n",
    "        rmsevec = vecfunc(h.data.numpy())\n",
    "        rmsevec = np.square(rmsevec - ratings.data.numpy())\n",
    "        rmses += np.sum(rmsevec)\n",
    "        cntr += len(rmsevec)\n",
    "        \n",
    "        batchcntr += 1\n",
    "    \n",
    "    rmses = rmses/(cntr+0.0)\n",
    "    rmses = np.sqrt(rmses)\n",
    "    \n",
    "    return rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BS = 1000\n",
    "num_epochs = 1\n",
    "eta = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data, this might take several minutes\n",
      "0 lines read\n",
      "100000 lines read\n",
      "200000 lines read\n",
      "300000 lines read\n",
      "400000 lines read\n",
      "500000 lines read\n",
      "600000 lines read\n",
      "700000 lines read\n",
      "800000 lines read\n",
      "900000 lines read\n",
      "1000000 lines read\n",
      "1100000 lines read\n",
      "1200000 lines read\n",
      "1300000 lines read\n",
      "1400000 lines read\n",
      "1500000 lines read\n",
      "1600000 lines read\n",
      "1700000 lines read\n",
      "Data Loaded\n"
     ]
    }
   ],
   "source": [
    "train_iter, val_iter, test_iter, text_field = utils.load_jester(batch_size=BS, subsample_rate=1.0, load_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V = len(text_field.vocab)\n",
    "usefulvec = Variable(torch.LongTensor([x for x in range(0,V)]))\n",
    "batchcntr = 0\n",
    "w = torch.nn.Embedding(V,1,padding_idx=text_field.vocab.stoi['<pad>'])\n",
    "sig = Variable(torch.Tensor([1]),requires_grad = True)\n",
    "optimizer = torch.optim.SGD([w.weight,sig],lr = eta)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_iter.init_epoch()\n",
    "    for batch in train_iter:\n",
    "        text = batch.text[0]\n",
    "        ratings = batch.ratings-1\n",
    "        users = batch.users-1\n",
    "        jokes = batch.jokes-1\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = logpost(w,sig,text,ratings)\n",
    "        \n",
    "        loss.backward()\n",
    "            \n",
    "        optimizer.step()\n",
    "        \n",
    "        batchcntr += 1\n",
    "#         print batchcntr,\"batch completed!\"\n",
    "        \n",
    "        if batchcntr == 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#     lefts = [-20]*len(val_range)\n",
    "#     rights = [-20]*len(val_range) \n",
    "#     for i in range(0,len(val_range)):\n",
    "#         lefts[i] = range_boundaries[ratings[i]]\n",
    "#         rights[i] = range_boundaries[ratings[i]+1]      \n",
    "#     normlogcdflik = utils.log_difference((Variable(torch.Tensor(rights))-h)/(sig),(Variable(torch.Tensor(lefts))-h)/(sig))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logposte(w,sig,x,ratings): # w is Embedding, sig is Variable, x is input data in tensor form, ratings is just ratings                 \n",
    "    h = torch.sum(w(x),1) #.squeeze()\n",
    "    \n",
    "    normlogcdflik = (-0.5/(sig**2))*torch.sum((ratings.type(torch.FloatTensor)-h)**2) \n",
    "    \n",
    "    normlogcdfprior = -0.5*torch.sum(w(usefulvec)*w(usefulvec))\n",
    "    \n",
    "    return torch.prod(torch.sum(normlogcdfprior+normlogcdflik), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V = len(text_field.vocab)\n",
    "usefulvec = Variable(torch.LongTensor([x for x in range(0,V)]))\n",
    "batchcntr = 0\n",
    "w = torch.nn.Embedding(V,1,padding_idx=text_field.vocab.stoi['<pad>'])\n",
    "sig = Variable(torch.Tensor([1]),requires_grad = True)\n",
    "optimizer = torch.optim.SGD([w.weight,sig],lr = eta)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_iter.init_epoch()\n",
    "    for batch in train_iter:\n",
    "        text = batch.text[0]\n",
    "        ratings = batch.ratings-1\n",
    "        users = batch.users-1\n",
    "        jokes = batch.jokes-1\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = logposte(w,sig,text,ratings)\n",
    "        loss.backward()\n",
    "            \n",
    "        optimizer.step()\n",
    "        \n",
    "        batchcntr += 1\n",
    "        \n",
    "        if batchcntr == 2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
